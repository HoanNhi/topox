{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d425cf-b018-41c3-acb6-4d7bc582dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:00.620809Z",
     "start_time": "2025-11-18T12:54:51.177477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "[11, 17, 27, 13, 33, 22, 29, 35, 25, 19, 16, 23, 31, 32, 28, 36, 12, 30, 24, 18, 20, 26, 14, 21, 34, 15]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "def parse_hypergraph(filename):\n",
    "    vertices = {}\n",
    "    simplices = []\n",
    "    index_to_labels = []\n",
    "\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            # vertex line\n",
    "            if line.startswith(\"v \"):\n",
    "                _, vid, label = line.split()\n",
    "                try:\n",
    "                    index = index_to_labels.index(int(label))\n",
    "                    vertices[int(vid)] = index\n",
    "                except:\n",
    "                    index_to_labels.append(int(label))\n",
    "                    vertices[int(vid)] = index_to_labels.index(int(label))\n",
    "                # vertices[int(vid)] = label\n",
    "\n",
    "            else:\n",
    "                # simplex line\n",
    "                parts = line.split(\"-\")\n",
    "                verts = list(map(int, parts[0].split()))\n",
    "                label = parts[1].strip()\n",
    "                simplices.append((verts, label))\n",
    "\n",
    "    return vertices, simplices, index_to_labels\n",
    "\n",
    "\n",
    "def incidence_matrix(vertices, simplices):\n",
    "    n = len(vertices)\n",
    "    m = len(simplices)\n",
    "\n",
    "    rows = []\n",
    "    cols = []\n",
    "\n",
    "    for e_idx, (verts, _) in enumerate(simplices):\n",
    "        for v in verts:\n",
    "            rows.append(v)\n",
    "            cols.append(e_idx)\n",
    "\n",
    "    indices = torch.tensor([rows, cols])\n",
    "    values = torch.ones(len(rows))\n",
    "\n",
    "    H_sparse = torch.sparse_coo_tensor(indices, values, size=(n, m)).to(device)\n",
    "\n",
    "    return H_sparse\n",
    "\n",
    "\n",
    "# Usage:\n",
    "vertices, simplices, index_to_labels = parse_hypergraph(\"OpenAlex\")\n",
    "H = incidence_matrix(vertices, simplices)\n",
    "print(index_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcd8391-7e2c-464c-b0a5-38da76a72373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987ba33ee1169056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:01.407360Z",
     "start_time": "2025-11-18T12:55:00.632536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (2480232, 36)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------------------\n",
    "# 1. Load patterns\n",
    "# --------------------\n",
    "def load_patterns(pattern_file):\n",
    "    patterns = []\n",
    "    with open(pattern_file) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"Time\") or line.startswith(\"Memory\") or line.startswith(\"-\"):\n",
    "                continue\n",
    "            patterns.append(line)\n",
    "    return sorted(list(set(patterns)))   # unique patterns\n",
    "\n",
    "# --------------------\n",
    "# 2. Load mapping (pattern → node)\n",
    "# --------------------\n",
    "def load_pattern_to_nodes(mapping_file):\n",
    "    pattern_to_nodes = defaultdict(set)\n",
    "\n",
    "    with open(mapping_file) as f:\n",
    "        for line in f:\n",
    "            pattern, node = line.strip().split(\"\\t\")\n",
    "            node = int(node)\n",
    "            pattern_to_nodes[pattern].add(node)\n",
    "\n",
    "    return pattern_to_nodes\n",
    "\n",
    "# --------------------\n",
    "# 3. Build feature matrix\n",
    "# --------------------\n",
    "def build_feature_matrix(patterns, pattern_to_nodes, N):\n",
    "    P = len(patterns)\n",
    "\n",
    "    node_to_row = {node: node for node in range(0, N)}\n",
    "    pattern_to_col = {p: j for j, p in enumerate(patterns)}\n",
    "\n",
    "    X = np.zeros((N, P), dtype=np.int8)\n",
    "\n",
    "    for p in patterns:\n",
    "        col = pattern_to_col[p]\n",
    "        for node in pattern_to_nodes.get(p, []):\n",
    "            row = node_to_row[node]\n",
    "            X[row, col] = 1\n",
    "\n",
    "    return X, node_to_row, pattern_to_col\n",
    "\n",
    "\n",
    "# ============================\n",
    "#       USAGE\n",
    "# ============================\n",
    "\n",
    "patterns = load_patterns(\"OpenAlex_freq_5000_minDim_0_maxSize_5\")\n",
    "pattern_to_nodes = load_pattern_to_nodes(\"OpenAlex_freq_5000_minDim_0_maxSize_5occMap\")\n",
    "\n",
    "X, node_to_row, pattern_to_col = build_feature_matrix(patterns, pattern_to_nodes, len(vertices))\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181dc4af32bb6985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:04.365135Z",
     "start_time": "2025-11-18T12:55:01.667465Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_vertex_labels(filename):\n",
    "    \"\"\"\n",
    "    Parse vertex labels from file with lines:\n",
    "    v <node> <label>\n",
    "    \"\"\"\n",
    "    labels = {}  # node_id → label\n",
    "\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            if line.startswith(\"v \"):\n",
    "                _, node_id, label = line.split()\n",
    "                node_id = int(node_id)\n",
    "                label = int(label)   # or str(label) if your labels are strings\n",
    "                labels[node_id] = index_to_labels.index(label)\n",
    "\n",
    "    return labels\n",
    "labels_dict = load_vertex_labels(\"OpenAlex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22eaf7ee-6a3c-4437-bb43-167859de69a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(index_to_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a22a6b66bfd30e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:15.661274Z",
     "start_time": "2025-11-18T12:55:04.839691Z"
    }
   },
   "outputs": [],
   "source": [
    "N = max(labels_dict.keys()) + 1\n",
    "y = torch.zeros(N, dtype=torch.long).to(device)\n",
    "\n",
    "for node, label in labels_dict.items():\n",
    "    y[node] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23aa4eee3477026d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:16.052049Z",
     "start_time": "2025-11-18T12:55:16.047149Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca000c988608555c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:18.109283Z",
     "start_time": "2025-11-18T12:55:16.113562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780 520 2478932\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def stratified_split(y, train_size=30, val_size=20):\n",
    "    \"\"\"\n",
    "    y: tensor of shape [N] containing class labels\n",
    "    \"\"\"\n",
    "    label_to_nodes = defaultdict(list)\n",
    "\n",
    "    # Group nodes by their labels\n",
    "    for node, label in enumerate(y.tolist()):\n",
    "        label_to_nodes[label].append(node)\n",
    "\n",
    "    train_idx = []\n",
    "    val_idx = []\n",
    "    test_idx = []\n",
    "\n",
    "    # Stratified sampling for each class\n",
    "    for label, nodes in label_to_nodes.items():\n",
    "        nodes = nodes.copy()\n",
    "        random.shuffle(nodes)\n",
    "\n",
    "        n = len(nodes)\n",
    "        t = min(train_size, n)      # in case some classes have fewer samples\n",
    "        v = min(val_size, n - t)\n",
    "\n",
    "        train_idx.extend(nodes[:t])\n",
    "        val_idx.extend(nodes[t:t+v])\n",
    "        test_idx.extend(nodes[t+v:])  # remaining\n",
    "\n",
    "    return train_idx, val_idx, test_idx\n",
    "\n",
    "train_idx, val_idx, test_idx = stratified_split(y)\n",
    "\n",
    "print(len(train_idx), len(val_idx), len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff2738d03ba50a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:19.381516Z",
     "start_time": "2025-11-18T12:55:18.520796Z"
    }
   },
   "outputs": [],
   "source": [
    "train_mask = torch.zeros(N, dtype=torch.bool).to(device)\n",
    "val_mask   = torch.zeros(N, dtype=torch.bool).to(device)\n",
    "test_mask  = torch.zeros(N, dtype=torch.bool).to(device)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "val_mask[val_idx]     = True\n",
    "test_mask[test_idx]   = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e91205608ab02a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:20.030140Z",
     "start_time": "2025-11-18T12:55:19.603743Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_edge_features(simplices):\n",
    "#     edge_labels = []\n",
    "#     for verts, label in simplices:\n",
    "#         edge_labels.append(int(label))\n",
    "\n",
    "#     edge_features = torch.tensor(edge_labels, dtype=torch.long)\n",
    "#     return edge_features\n",
    "\n",
    "# edge_features = build_edge_features(simplices)\n",
    "# print(edge_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be13ad1eaac5700c",
   "metadata": {},
   "source": [
    "## Section: Hear comes nothing (HMPNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8723be0-3b2c-4ba1-b558-275ec966bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install topomodelx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c62cbbb86e389a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:21.183814Z",
     "start_time": "2025-11-18T12:55:20.088190Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from topomodelx.nn.hypergraph.hmpnn import HMPNN\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    \"\"\"Network class that initializes the base model and readout layer.\n",
    "\n",
    "    Base model parameters:\n",
    "    ----------\n",
    "    Reqired:\n",
    "    in_channels : int\n",
    "        Dimension of the input features.\n",
    "    hidden_channels : int\n",
    "        Dimension of the hidden features.\n",
    "\n",
    "    Optitional:\n",
    "    **kwargs : dict\n",
    "        Additional arguments for the base model.\n",
    "\n",
    "    Readout layer parameters:\n",
    "    ----------\n",
    "    out_channels : int\n",
    "        Dimension of the output features.\n",
    "    task_level : str\n",
    "        Level of the task. Either \"graph\" or \"node\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, in_channels, hidden_channels, out_channels, task_level=\"graph\", **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the model\n",
    "        self.base_model = HMPNN(\n",
    "            in_channels=in_channels, hidden_channels=hidden_channels, **kwargs\n",
    "        )\n",
    "\n",
    "        # Readout\n",
    "        self.linear = torch.nn.Linear(hidden_channels, 512)\n",
    "        self.outputLayer = torch.nn.Linear(512, out_channels)\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.out_pool = task_level == \"graph\"\n",
    "\n",
    "    def forward(self, x_0, x_1, incidence_1):\n",
    "        # Base model\n",
    "        x_0, x_1 = self.base_model(x_0, x_1, incidence_1)\n",
    "\n",
    "        # Pool over all nodes in the hypergraph\n",
    "        x = torch.max(x_0, dim=0)[0] if self.out_pool is True else x_0\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.outputLayer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce3de12722000d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:21.468002Z",
     "start_time": "2025-11-18T12:55:21.463756Z"
    }
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e58eccedb01394f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:21.633951Z",
     "start_time": "2025-11-18T12:55:21.543663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base model hyperparameters\n",
    "in_channels = X.shape[1]\n",
    "hidden_channels = 256\n",
    "n_layers = 8\n",
    "\n",
    "# Readout hyperparameters\n",
    "out_channels = torch.unique(y).shape[0]\n",
    "task_level = \"graph\" if out_channels == 1 else \"node\"\n",
    "\n",
    "\n",
    "model = Network(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=hidden_channels,\n",
    "    out_channels=out_channels,\n",
    "    n_layers=n_layers,\n",
    "    task_level=task_level,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "413d98ef92599f6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:21.735553Z",
     "start_time": "2025-11-18T12:55:21.666839Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float).to(device)\n",
    "# edge_features = torch.tensor(edge_features, dtype=torch.float).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e1a0b4f1306f4ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:21.760473Z",
     "start_time": "2025-11-18T12:55:21.754739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2480232, 36])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f43c7d3855eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:55:53.808068Z",
     "start_time": "2025-11-18T12:55:21.854230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 train loss: 3.2768 train acc: 0.03  val loss: 4.4717 val acc: 0.04\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    min_lr = 1e-6\n",
    ")\n",
    "\n",
    "torch.manual_seed(100)\n",
    "test_interval = 5\n",
    "num_epochs = 1000\n",
    "\n",
    "\n",
    "initial_x_1 = torch.zeros((H.shape[1], X.shape[1])).to(device)\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(X, initial_x_1, H)\n",
    "    # print(y_hat[train_mask])\n",
    "    # print(y[train_mask])\n",
    "    loss = loss_fn(y_hat[train_mask], y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss = loss.item()\n",
    "    y_pred = y_hat.argmax(dim=-1)\n",
    "    train_acc = accuracy_score(y[train_mask].cpu(), y_pred[train_mask].cpu())\n",
    "\n",
    "    model.eval()\n",
    "    y_hat = model(X, initial_x_1, H)\n",
    "    val_loss = loss_fn(y_hat[val_mask], y[val_mask]).item()\n",
    "    y_pred = y_hat.argmax(dim=-1)\n",
    "    val_acc = accuracy_score(y[val_mask].cpu(), y_pred[val_mask].cpu())\n",
    "\n",
    "    \n",
    "    # update LR\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    print(\n",
    "            f\"Epoch: {epoch + 1} train loss: {train_loss:.4f} train acc: {train_acc:.2f} \"\n",
    "            f\" val loss: {val_loss:.4f} val acc: {val_acc:.2f}\"\n",
    "        )\n",
    "\n",
    "    if epoch % test_interval == 0:\n",
    "        test_loss = loss_fn(y_hat[test_mask], y[test_mask]).item()\n",
    "        y_pred = y_hat.argmax(dim=-1)\n",
    "        test_acc = accuracy_score(y[test_mask].cpu(), y_pred[test_mask].cpu())\n",
    "        print(\n",
    "            f\"Epoch: {epoch + 1} train loss: {train_loss:.4f} train acc: {train_acc:.2f} \"\n",
    "            f\" test loss: {test_acc:.4f} test acc: {test_acc:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3025f80ef028291",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(X, initial_x_1, H)\n",
    "y_pred = y_hat.argmax(dim=-1)\n",
    "print(y_pred)\n",
    "\n",
    "print(torch.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c74a06d124aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(y).shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
